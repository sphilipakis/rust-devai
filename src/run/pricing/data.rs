use crate::run::pricing::{ModelPricing, ProviderPricing};

// Define Anthropic pricing
const ANTHROPIC_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "claude-opus-4-5",
		input_cached: Some(0.5),
		input_normal: 5.0,
		output_normal: 25.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "claude-opus-4-1",
		input_cached: Some(1.5),
		input_normal: 15.0,
		output_normal: 75.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "claude-opus-4",
		input_cached: Some(1.5),
		input_normal: 15.0,
		output_normal: 75.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "claude-sonnet-4-5",
		input_cached: Some(0.3),
		input_normal: 3.0,
		output_normal: 15.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "claude-sonnet-4",
		input_cached: Some(0.3),
		input_normal: 3.0,
		output_normal: 15.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "claude-3-7-sonnet",
		input_cached: Some(0.3),
		input_normal: 3.0,
		output_normal: 15.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "claude-haiku-4-5",
		input_cached: Some(0.1),
		input_normal: 1.0,
		output_normal: 5.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "claude-3-5-haiku",
		input_cached: Some(0.08),
		input_normal: 0.8,
		output_normal: 4.0,
		output_reasoning: None,
	},
];

const ANTHROPIC: ProviderPricing = ProviderPricing {
	name: "anthropic",
	models: ANTHROPIC_MODELS,
};

// Define Deepseek pricing
const DEEPSEEK_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "deepseek-chat",
		input_cached: Some(0.07),
		input_normal: 0.27,
		output_normal: 1.1,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-reasoner",
		input_cached: Some(0.14),
		input_normal: 0.55,
		output_normal: 2.19,
		output_reasoning: None,
	},
];

const DEEPSEEK: ProviderPricing = ProviderPricing {
	name: "deepseek",
	models: DEEPSEEK_MODELS,
};

// Define Fireworks pricing
const FIREWORKS_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "deepseek-v3p1-terminus",
		input_cached: None,
		input_normal: 0.56,
		output_normal: 1.68,
		output_reasoning: None,
	},
	ModelPricing {
		name: "glm-4p6",
		input_cached: None,
		input_normal: 0.55,
		output_normal: 2.19,
		output_reasoning: None,
	},
	ModelPricing {
		name: "kimi-k2-instruct",
		input_cached: None,
		input_normal: 0.6,
		output_normal: 2.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-v3p1",
		input_cached: None,
		input_normal: 0.56,
		output_normal: 1.68,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-oss-120b",
		input_cached: None,
		input_normal: 0.15,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-oss-20b",
		input_cached: None,
		input_normal: 0.07,
		output_normal: 0.3,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-235b-a22b-thinking",
		input_cached: None,
		input_normal: 0.22,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-coder-480b-a35b-instruct",
		input_cached: None,
		input_normal: 0.45,
		output_normal: 1.8,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-235b-a22b-instruct",
		input_cached: None,
		input_normal: 0.22,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "glm-4p5",
		input_cached: None,
		input_normal: 0.55,
		output_normal: 2.19,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-r1",
		input_cached: None,
		input_normal: 1.35,
		output_normal: 5.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-235b-a22b",
		input_cached: None,
		input_normal: 0.22,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen2p5-vl-32b-instruct",
		input_cached: None,
		input_normal: 0.9,
		output_normal: 0.9,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-v3",
		input_cached: None,
		input_normal: 0.9,
		output_normal: 0.9,
		output_reasoning: None,
	},
	ModelPricing {
		name: "llama-v3p3-70b-instruct",
		input_cached: None,
		input_normal: 0.9,
		output_normal: 0.9,
		output_reasoning: None,
	},
	ModelPricing {
		name: "kimi-k2-thinking",
		input_cached: None,
		input_normal: 1.2,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "minimax-m2",
		input_cached: None,
		input_normal: 0.3,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-vl-30b-a3b-thinking",
		input_cached: None,
		input_normal: 0.15,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-vl-30b-a3b-instruct",
		input_cached: None,
		input_normal: 0.15,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-reranker-8b",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-vl-235b-a22b-thinking",
		input_cached: None,
		input_normal: 0.22,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-vl-235b-a22b-instruct",
		input_cached: None,
		input_normal: 0.22,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-embedding-8b",
		input_cached: None,
		input_normal: 0.1,
		output_normal: 0.1,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen3-8b",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
];

const FIREWORKS: ProviderPricing = ProviderPricing {
	name: "fireworks",
	models: FIREWORKS_MODELS,
};

// Define Gemini pricing
const GEMINI_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "gemini-3-pro",
		input_cached: Some(0.2),
		input_normal: 2.0,
		output_normal: 12.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-3-pro-batch",
		input_cached: Some(0.2),
		input_normal: 1.0,
		output_normal: 6.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-3-flash",
		input_cached: Some(0.05),
		input_normal: 0.5,
		output_normal: 3.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-3-flash-batch",
		input_cached: Some(0.05),
		input_normal: 0.25,
		output_normal: 1.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.5-pro",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.5-pro-batch",
		input_cached: Some(0.125),
		input_normal: 0.625,
		output_normal: 5.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.5-flash",
		input_cached: Some(0.03),
		input_normal: 0.3,
		output_normal: 2.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.5-flash-batch",
		input_cached: Some(0.03),
		input_normal: 0.15,
		output_normal: 1.25,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.5-flash-lite",
		input_cached: Some(0.01),
		input_normal: 0.1,
		output_normal: 0.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.5-flash-lite-batch",
		input_cached: Some(0.01),
		input_normal: 0.05,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.0-flash",
		input_cached: Some(0.025),
		input_normal: 0.1,
		output_normal: 0.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.0-flash-batch",
		input_cached: Some(0.025),
		input_normal: 0.05,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.0-flash-lite",
		input_cached: None,
		input_normal: 0.075,
		output_normal: 0.3,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.0-flash-lite-batch",
		input_cached: None,
		input_normal: 0.0375,
		output_normal: 0.15,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-flash-latest",
		input_cached: Some(0.03),
		input_normal: 0.3,
		output_normal: 2.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-flash-latest-batch",
		input_cached: Some(0.03),
		input_normal: 0.15,
		output_normal: 1.25,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-pro-latest",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-pro-latest-batch",
		input_cached: Some(0.125),
		input_normal: 0.625,
		output_normal: 5.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-embedding-001",
		input_cached: None,
		input_normal: 0.15,
		output_normal: 0.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-robotics-er-1.5",
		input_cached: None,
		input_normal: 0.3,
		output_normal: 2.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemini-2.5-computer-use",
		input_cached: None,
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemma-3",
		input_cached: Some(0.0),
		input_normal: 0.0,
		output_normal: 0.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemma-3n",
		input_cached: Some(0.0),
		input_normal: 0.0,
		output_normal: 0.0,
		output_reasoning: None,
	},
];

const GEMINI: ProviderPricing = ProviderPricing {
	name: "gemini",
	models: GEMINI_MODELS,
};

// Define Groq pricing
const GROQ_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "openai/gpt-oss-20b",
		input_cached: None,
		input_normal: 0.1,
		output_normal: 0.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "openai/gpt-oss-120b",
		input_cached: None,
		input_normal: 0.15,
		output_normal: 0.75,
		output_reasoning: None,
	},
	ModelPricing {
		name: "moonshotai/kimi-k2-instruct",
		input_cached: None,
		input_normal: 1.0,
		output_normal: 3.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-4-scout-17b-16e-instruct",
		input_cached: None,
		input_normal: 0.11,
		output_normal: 0.34,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-4-maverick-17b-128e-instruct",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-guard-4-12b",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-r1-distill-llama-70b",
		input_cached: None,
		input_normal: 0.75,
		output_normal: 0.99,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-32b",
		input_cached: None,
		input_normal: 0.29,
		output_normal: 0.59,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistral-saba-24b-32k",
		input_cached: None,
		input_normal: 0.79,
		output_normal: 0.79,
		output_reasoning: None,
	},
	ModelPricing {
		name: "llama-3.3-70b-versatile",
		input_cached: None,
		input_normal: 0.59,
		output_normal: 0.79,
		output_reasoning: None,
	},
	ModelPricing {
		name: "llama-3.1-8b-instant",
		input_cached: None,
		input_normal: 0.05,
		output_normal: 0.08,
		output_reasoning: None,
	},
	ModelPricing {
		name: "llama3-70b-8k",
		input_cached: None,
		input_normal: 0.59,
		output_normal: 0.79,
		output_reasoning: None,
	},
	ModelPricing {
		name: "llama3-8b-8k",
		input_cached: None,
		input_normal: 0.05,
		output_normal: 0.08,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gemma2-9b-it",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "llama-guard-3-8b-8k",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
];

const GROQ: ProviderPricing = ProviderPricing {
	name: "groq",
	models: GROQ_MODELS,
};

// Define OpenAI pricing
const OPENAI_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "gpt-5.2",
		input_cached: Some(0.175),
		input_normal: 1.75,
		output_normal: 14.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5.1",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5-mini",
		input_cached: Some(0.025),
		input_normal: 0.25,
		output_normal: 2.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5-nano",
		input_cached: Some(0.005),
		input_normal: 0.05,
		output_normal: 0.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5.2-chat-latest",
		input_cached: Some(0.175),
		input_normal: 1.75,
		output_normal: 14.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5.1-chat-latest",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5-chat-latest",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5.1-codex-max",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5.1-codex",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5-codex",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5.2-pro",
		input_cached: None,
		input_normal: 21.0,
		output_normal: 168.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5-pro",
		input_cached: None,
		input_normal: 15.0,
		output_normal: 120.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-4.1",
		input_cached: Some(0.5),
		input_normal: 2.0,
		output_normal: 8.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-4.1-mini",
		input_cached: Some(0.1),
		input_normal: 0.4,
		output_normal: 1.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-4.1-nano",
		input_cached: Some(0.025),
		input_normal: 0.1,
		output_normal: 0.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-4o",
		input_cached: Some(1.25),
		input_normal: 2.5,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-4o-mini",
		input_cached: Some(0.075),
		input_normal: 0.15,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o1",
		input_cached: Some(7.5),
		input_normal: 15.0,
		output_normal: 60.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o1-pro",
		input_cached: None,
		input_normal: 150.0,
		output_normal: 600.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o3-pro",
		input_cached: None,
		input_normal: 20.0,
		output_normal: 80.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o3",
		input_cached: Some(0.5),
		input_normal: 2.0,
		output_normal: 8.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o3-deep-research",
		input_cached: Some(2.5),
		input_normal: 10.0,
		output_normal: 40.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o4-mini",
		input_cached: Some(0.275),
		input_normal: 1.1,
		output_normal: 4.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o4-mini-deep-research",
		input_cached: Some(0.5),
		input_normal: 2.0,
		output_normal: 8.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o3-mini",
		input_cached: Some(0.55),
		input_normal: 1.1,
		output_normal: 4.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "o1-mini",
		input_cached: Some(0.55),
		input_normal: 1.1,
		output_normal: 4.4,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5.1-codex-mini",
		input_cached: Some(0.025),
		input_normal: 0.25,
		output_normal: 2.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "codex-mini-latest",
		input_cached: Some(0.375),
		input_normal: 1.5,
		output_normal: 6.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "gpt-5-search-api",
		input_cached: Some(0.125),
		input_normal: 1.25,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		// Renamed computer-use-preview
		name: "computer-use",
		input_cached: None,
		input_normal: 3.0,
		output_normal: 12.0,
		output_reasoning: None,
	},
];

const OPENAI: ProviderPricing = ProviderPricing {
	name: "openai",
	models: OPENAI_MODELS,
};

// Define XAI pricing
const XAI_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "grok-4",
		input_cached: Some(0.75),
		input_normal: 3.0,
		output_normal: 15.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-3",
		input_cached: Some(0.75),
		input_normal: 3.0,
		output_normal: 15.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-3-mini",
		input_cached: Some(0.075),
		input_normal: 0.3,
		output_normal: 0.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-3-fast",
		input_cached: Some(1.25),
		input_normal: 5.0,
		output_normal: 25.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-3-mini-fast",
		input_cached: Some(0.15),
		input_normal: 0.6,
		output_normal: 4.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-beta",
		input_cached: None,
		input_normal: 5.0,
		output_normal: 15.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-2-image-gen",
		input_cached: None,
		input_normal: 0.0,
		output_normal: 0.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-2-vision-1212",
		input_cached: None,
		input_normal: 2.0,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-2-1212",
		input_cached: None,
		input_normal: 2.0,
		output_normal: 10.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-vision-beta",
		input_cached: None,
		input_normal: 5.0,
		output_normal: 15.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "grok-2-image-1212",
		input_cached: None,
		input_normal: 0.0,
		output_normal: 0.07,
		output_reasoning: None,
	},
];

const XAI: ProviderPricing = ProviderPricing {
	name: "xai",
	models: XAI_MODELS,
};

const TOGETHER_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "deepcogito/cogito-v2-preview-deepseek-671b",
		input_cached: None,
		input_normal: 1.25,
		output_normal: 1.25,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1",
		input_cached: None,
		input_normal: 3.0,
		output_normal: 7.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-0528-tput",
		input_cached: None,
		input_normal: 0.55,
		output_normal: 2.19,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-distill-llama-70b",
		input_cached: None,
		input_normal: 2.0,
		output_normal: 2.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-distill-qwen-1.5b",
		input_cached: None,
		input_normal: 0.18,
		output_normal: 0.18,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-distill-qwen-14b",
		input_cached: None,
		input_normal: 1.6,
		output_normal: 1.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-v3",
		input_cached: None,
		input_normal: 1.25,
		output_normal: 1.25,
		output_reasoning: None,
	},
	ModelPricing {
		name: "google/gemma-2-27b-it",
		input_cached: None,
		input_normal: 0.8,
		output_normal: 0.8,
		output_reasoning: None,
	},
	ModelPricing {
		name: "google/gemma-3n-e4b-it",
		input_cached: None,
		input_normal: 0.02,
		output_normal: 0.04,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-2-70b-hf",
		input_cached: None,
		input_normal: 0.9,
		output_normal: 0.9,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3-70b-chat-hf",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3-8b-chat-hf",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3.2-3b-instruct-turbo",
		input_cached: None,
		input_normal: 0.06,
		output_normal: 0.06,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3.3-70b-instruct-turbo",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
		input_cached: None,
		input_normal: 0.27,
		output_normal: 0.85,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-4-scout-17b-16e-instruct",
		input_cached: None,
		input_normal: 0.18,
		output_normal: 0.59,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3-70b-instruct-turbo",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3-8b-instruct-lite",
		input_cached: None,
		input_normal: 0.1,
		output_normal: 0.1,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3.1-405b-instruct-turbo",
		input_cached: None,
		input_normal: 3.5,
		output_normal: 3.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3.1-70b-instruct-turbo",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3.1-8b-instruct-turbo",
		input_cached: None,
		input_normal: 0.18,
		output_normal: 0.18,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-7b-instruct-v0.1",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-7b-instruct-v0.2",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-7b-instruct-v0.3",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-small-24b-instruct-2501",
		input_cached: None,
		input_normal: 0.8,
		output_normal: 0.8,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mixtral-8x7b-instruct-v0.1",
		input_cached: None,
		input_normal: 0.6,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
		input_cached: None,
		input_normal: 0.6,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "nvidia/llama-3.1-nemotron-70b-instruct-hf",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "openai/gpt-oss-120b",
		input_cached: None,
		input_normal: 0.15,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "openai/gpt-oss-20b",
		input_cached: None,
		input_normal: 0.05,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwq-32b",
		input_cached: None,
		input_normal: 1.2,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2-72b-instruct",
		input_cached: None,
		input_normal: 0.9,
		output_normal: 0.9,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2-vl-72b-instruct",
		input_cached: None,
		input_normal: 1.2,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2.5-72b-instruct-turbo",
		input_cached: None,
		input_normal: 1.2,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2.5-7b-instruct-turbo",
		input_cached: None,
		input_normal: 0.3,
		output_normal: 0.3,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2.5-vl-72b-instruct",
		input_cached: None,
		input_normal: 1.95,
		output_normal: 8.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-235b-a22b-fp8-tput",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-235b-a22b-instruct-2507-tput",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-235b-a22b-thinking-2507",
		input_cached: None,
		input_normal: 0.65,
		output_normal: 3.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-coder-480b-a35b-instruct-fp8",
		input_cached: None,
		input_normal: 2.0,
		output_normal: 2.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "zai-org/glm-4.5-air-fp8",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 1.1,
		output_reasoning: None,
	},
];

const TOGETHER: ProviderPricing = ProviderPricing {
	name: "together",
	models: TOGETHER_MODELS,
};

pub const PROVIDERS: &[ProviderPricing] = &[OPENAI, GROQ, GEMINI, DEEPSEEK, ANTHROPIC, XAI, FIREWORKS, TOGETHER];
